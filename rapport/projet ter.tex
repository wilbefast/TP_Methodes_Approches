\documentclass[a4paper, 12pt]{report}
\usepackage[utf8]{inputenc} 
\usepackage[frenchb]{babel}
\usepackage{fullpage}
\usepackage[T1]{fontenc} 
\usepackage{graphicx} 
\usepackage[final]{pdfpages}
\usepackage{amsmath, amssymb, wasysym, amsthm}
\usepackage{listingsutf8}
\usepackage{lmodern}
\usepackage{tikz}
\usepackage{pgfplots}

\newtheorem{mydef}{Définition}
\newtheorem{thm}{Théorème}
\newtheorem{lem}{Lemme}
\newtheorem{cor}{Corollaire}
\newtheorem{prop}{Propriété}
\newtheorem{pro}{Proposition}

\title{Rapport de stage: Approximation of min-max and min-max regret versions of some combinatorial optimization problems}
\author{Loukil Amal: \\ M1 MOCA}
\date{semestre 2 : 2011-2012}

\begin{document} 

\maketitle

\begin{abstract}
Les critères min-max et min-max regret sont souvent utilisés en vue d'obtenir des solutions robustes.Dans ce thème, cet article étudie l'approximation des versions min-max et min-max regret de quelques problèmes classiques tels que le plus court chemin, l'arbre couvrant de poids minimum et le problème de sac à dos,pour lesquels nous présentons des résultats positifs et négatifs.
\end{abstract}


\pagebreak

\tableofcontents

\pagebreak

\listoftables
\pagebreak

\section{Introduction}

La définition d'une instance d'un problème d'optimisation combinatoire nécessite de préciser les paramètres, en particulier les coefficients de la fonction objective, qui peut être incertaine ou imprécise.
L'incertitude, l'imprécision peuvent être structuré par le biais de concept de scénario qui correspond à affecter des valeurs plausibles aux paramètres du modèle.
Il existe deux façons naturelles pour décrire l'ensemble de tous les scénarios possibles.Dans le cas des données d'intervalle, chaque paramètre numérique peut prendre n'importe quelle valeur entre la borne inférieure et la borne supérieure de l'intervalle. Dans le scénario discret, S est décrite de manière explicite par la liste de tous les vecteurs s $\epsilon$ S. Dans ce cas, nous distinguons des situations où le nombre de scénarios est délimitée par une constante de ceux où le nombre de scénarios est sans bornes.
Kouvelis et Yu ont proposé les critères min-max et min-max regret, résultant de la théorie de la décision, pour construire des solutions pour se prémunir contre les variations des paramètres.
Dans ce sens, pour un nombre de scénario constant,on établit un schem

\section{Etude de complexité}

La complexité des versions min-max et min-max regret a été largement étudiée au cours de la dernière décennie. Kouvelis et Yu ont étudié la complexité de min-max et  min-max regret, pour le cas de scénario discret, de plusieurs problèmes d'optimisation combinatoire, y compris le plus court chemin, arbre couvrant de poids minimum et le problèmede sac à dos.
En général, ces versions ont été montré pour être plus difficile que les versions classiques. Les versions Min-max(regret) des problèmes polynomiaux deviennent généralement faiblement NP-difficile pour un nombre constant de scénarios, et fortement NP-difficile pour un nombre non-constant de scénarios.

\section{Définitions des problèmes étudiés}

\subsection{Le plus court chemin }
	Les problèmes de cheminement sont des problèmes classiques de la théorie des graphes. L'objectif est de calculer une route entre des sommets d'un graphe qui minimise ou maximise une certaine fonction économique.
Le problème le plus classique consiste à chercher le chemin qui minimise la somme des valuations des arêtes traversées.
\subsection{Arbre couvrant de poids minimal}
	En théorie des graphes, étant donné un graphe non orienté connexe dont les arêtes sont pondérées, un arbre couvrant de poids minimal de ce graphe est un arbre couvrant dont la somme des poids des arêtes est minimale.
\subsection{Sac à dos}
	Le problème du sac à dos est un problème d'optimisation combinatoire. Il modélise une situation analogue au remplissage d'un sac à dos, ne pouvant supporter plus d'un certain poids, avec tout ou partie d'un ensemble donné d'objets ayant chacun un poids et une valeur. Les objets mis dans le sac à dos doivent maximiser la valeur totale, sans dépasser le poids maximum.
	
	
\section{Préliminaire}
	On considère la classe C définie comme suit:
$$
\left\lbrace 
\begin{array}{r r r}
${\min\sum_{i=1}^{n} c_{i} x_{i} $   $c_{i}$ $\epsilon$ $\mathbb{N}$\\ 
$x $\epsilon$ X $\subset \{0,1\}^n$
\end{array} 
\right. 
$$
Cette classe comprend une grande variété de problèmes combinatoires, dont certains se résolvent en temps polynomial (problème du plus court chemin, arbre couvrant de poids minimal...) et d'autres sont NP-difficiles (sac à dos...).\\
La taille d'une solution x $\epsilon$ X est le nombre de variables $x_{i}$ qui sont égale à 1.
\section{Généralité}
	Etant donnée un problème $P$ $\epsilon$ $C$, la version min-max(regret) associée au problème $P$ possède comme entrée un ensemble finie de scénarios S où chaque scénario s $\epsilon$ S est représenté par un vecteur ($c_{1}^s,...,c_{n}^s$). On note par $val(x,s)=\sum_{i=1}^n c_{i}^s x_{i}$, la valeur de la solution x $\epsilon$ X sous le scénario s $\epsilon$ S et par $val_{s}^*$ la valeur optimale du scénario s.
	
\subsection{Min-max}
	Le problème d'optimisation min-max associé à $P$, noté par Min-Max $P$, consiste à trouver une solution x,  parmi tous les scénarios, ayant le meilleur possible performance dans le pire de cas et qui s'écrit comme suit:
	$\min_{x $\in$ X}\[\max_{s $\in$ S}val(x,s)$ 
\subsection{Min-max regret}
	Etant donnée une solution x $\in$ X, son regret R(x,s), sous un scénario s $\in$ S est définie comme suit:\\
							\begin{center}
							$R(x,s)$=$val(x,s)$-$ $val_{s}^*$ $\\
							\end{center}
	Le regret maximum $R_{max}(x)$ d'une solution x est donc définie comme:\\
	\begin{center}
	$$R_{max}(x)$ $=$ $\underset{s $\in$ S}{\max}R(x,s)$ $.  
	\end{center} 
		Le problème d'optimisation min_max regret associé à $P$, noté par Min-Max regret $P$, consiste à trouver une solution x qui minimise le regret maximum $R_{max}(x)$. 
\section{Illustration}
	Afin d'illustrer les définitions précédentes et de montrer l'intérêt de l'utilisation des critères min-max et  min-max regret, on considère le problème de sac à dos, où on cherche un sous ensemble $I$ $\subseteq$ $\lbrace1,....,$n$\rbrace$ d'objets tel que $w_{i}$ $\leqslant$ $b$ et qui maximisent \sum_{i}$p_{i}$. 
	\subsection{Exemple numérique}
	Dans cette exemple, on considère trois scénarios où chaque scénario est représenté par un vecteur $p_{i}^s$ avec s $\in$ $\lbrace1,2,3\rbrace$. On prend $b$ $=$12 et $n$ $=$ 6.\\

\begin{table}	
\begin{center}
	\begin{tabular}{|c|c|c|c|c|}
	\hline
    $i$ & $w_{i}$ & $p_{i}^1$ & $p_{i}^2$ & $p_{i}^3$ \\ 
    \hline
    1 & 3 & 4 & 3 & 3\\
    \hline
    2 & 5 & 8 & 4 & 6\\
      \hline
	3 & 2 & 5 & 3 & 3\\
	  \hline
	4 & 4 & 3 & 2 & 4\\
	  \hline
	5 & 5 & 2 & 8 & 2\\
	  \hline
	6 & 3 & 4 & 6 & 2\\
	\hline
\end{tabular}
\end{center}
\caption {Poids et valeurs des objets}
\end{table}\\

\begin{table}	
\begin{center}
	\begin{tabular}{|c|c|c|c|}
    \hline
    1 & 2 & 3 & solution optimale\\
    \hline
    17 & 10 & 12 & scénario1(1,1,1,0,0,0)\\
     \hline
	11 & 17 & 7 & scénario2(0,0,1,0,1,1)\\
\hline
	16 & 9 & 13 & scénario3(0,1,1,1,0,0)\\
	  \hline
	15 & 12 & 12 & max-min(0,1,0,1,0,1)\\
	\hline
	15 & 15 & 11 & min-max regret(0,1,1,0,1,0)\\
	\hline
\end{tabular}
\end{center}
\caption {Solution et valeur optimale}
\end{table}\\

	On observe dans le tableau 2 que les solutions optimales des trois scénarios ne sont pas complètement satisfaisantes car ils donnent de faibles valeurs dans certains scénarios. Une solution appropriée devrait bien se comporter en fonction de toute variation des futures valeurs. Dans cet exemple, des solutions optimales à max-min et min-max regret sont des solutions plus acceptables, car leurs performances sont plus stables.


\section{Approximation}
	Considérons une instance $I$, de taille |$I$|, d'un problème d'optimisation et\\
	une solution x de l'instance $I$.
On note la valeur optimale de $I$ par opt($I$). L'indice de performance de x est r(x)=\max\lbrace\[\frac{val(x)}{opt(I)},\[\frac{opt(I)}{val(x)}\]\rbrace.\\
	soit $f$ une fonction, un algorithme est dit f(n)$-$approximable si pour toute instance $I$ du problème,\\
	il renvoie une solution x tel que r(x) $\leqslant$ f|$I$|.\\ 
	Un problème d'optimisation admet un schèma d'approximation totalement polynomial, si pour toute constante $\epsilon$ $\>$ 0, il admet un algorithme (1+ $\epsilon$)$-$approximable dont le temps d'exécution est bornée polynomialement par un polynome en 1/ $\epsilon$ $*$ un polynome en n la taille.
\subsection{Gap-introducing reduction}
	Soit $P$ un problème de décision et $Q$ un problème de minimisation. On dit que $P$ est gap-introducing reductible à $Q$ s'il existe une fonction $f$ calculable en temps polynomile et une constante $\alpha$ $\>$ 0 tel que, étant donné une instance $I$ de $P$, il est possible de construire en temps polynomiale une instance $I'$ de $Q$ tel que 
\begin{itemize}
\item[• si $I$ est une instance positive alors opt($I$') $\leqslant$ $f$($I'$)]
\item[• si $I$ est une instance négative alors opt($I'$)>&\alpha $f$($I'$)]
\end{itemize}
\begin{lem}
si P est un problème NP-complet et P est gap-introducing reducible à Q alors Q est non $\alpha$-approximable si $P$ $\neq$ $NP$.
\end{lem} 

\section{Etude de la relation entre min-max(regret) et optimisation multi-objective}
	Il est naturel de considérer les scénarios comme des fonctions objectives. Cela nous amène à étudier les relations entre min-max(regret) et les versions multi-objectifs.
La version multi-objective associée à un problème $P$ $\in$ $C$, notée par Multi-objective $P$, possède en entreé $K$ fonctions objectives où les coefficients de la hth fonction objective sont définies par le vecteur 
($c_{1}^s,...,c_{n}^s$).
On note par $val(x,h)=\sum_{i=1}^n c_{i}^h x_{i}$ la valeur de la solution x $\in$ X dans le scénario h et on suppose qu'on minimise tous les scénarios. 	
Etant donnée deux solutions réalisables $x$ et $y$, on dit que $x$ domine $y$ si val(x,h) $\leq$ val(y,h) pour 
$h = 1,. . . , K$ avec au moins une inégalité stricte.
	 Le problème consiste à trouver l'ensemble E des solutions efficaces. Une solution réalisable $x$ est efficace s'il n'y a pas d'autre solution réalisable $y$ qui domine $x$.
	\begin{itemize}
 \item Illustration:
 On peut représenter l'ensemble des fonctions objectives k comme suit:
 \left\{\[\min\[\sum_{i=1}^{n} c_{i}^h x_{i}\] \[c_{i}\] \epsilon \Bbbn\\ x \epsilon X  \subset \{0,1\}^n
 \right.
 	\end{itemize}   
\begin{thm}
	Etant donné un problème de minimisation $P$, au moins une solution optimale pour Min-Max $P$ est nécessairement une solution efficace.
\end{thm}
\begin{proof}\\
Si x $\in$ X domine y $\in$ X, alors \max_{s $\in$ S} val(x,s)$\leq$ \max_{s $\in$ S} val(y,s). Par conséquent, nous obtenons une solution optimale pour Min-Max $P$ en prenant parmi les solutions efficaces, une solution qui a le \min \max{s $\in$ S} val(x,s).
\end{proof}
\begin{thm}
Etant donné un problème de minimisation $P$, au moins une solution optimale pour Min-Max regret $P$ est nécessairement une solution efficace.
\end{thm}
\begin{proof}\\
Si x $\in$ X domine y $\in$ X, alors val(x,s)$\leq$val(y,s), pour chaque s $\in$ S et donc 
Rmax (x)$\leq$ Rmax (y). Par conséquent, nous obtenons une solution optimale pour Min-Max regret $P$ en prenant parmi les solutions efficaces, une solution x qui a le minimum Rmax (x).
\end{proof}
\section{Min-Max regret du problème sac à dos}
	Dans cette section, on va prouver que min-max regret du problème sac à dos n'est pas approximable. 
\subsection{Etapes}
	Comme première étape, on va constuire une gap-introducing reduction à partir du problème partition qui est connu NP-complet.
	\begin{mydef}{partition}\\
Entrée: Un ensemble finie d'objets $A$ et $s($a$)$ représente la taille de l'objet $a$ $\in$ $A$.\\
Question: Existe t-il une partition de l'ensemble $A$ en deux sous ensembles ($A'$, $A$\setminus$A'$)\\ avec $A'$ $\subset$ $A$ tel que $\sum_{ a $\in$ A$\setminus$A'} s(a).
\end{mudef} \\
	Considérons une instance $I$ de partition caractérisé par un ensemble $A$ $=$ $\lbrace $a_{0}$, $a_{1}$,.....$a_{n-1}$\rbrace$ de $n$ objets et de taille s($a$) pour chaque $a$ $\in$ $A$.\\
	On définit une instance $I'$ de min-max regret du problème sac à dos comme suit:\\
\begin{itemize}	
	\item soit $n+1$ objets.
	\item La capacité du sac est $d$$=$$\sum_{a$\in$A}s($a$)
	\item Pour $i$ $=$ 0,...,$n-1$, le poids de $i$ est $w_{i}$=$s(a_{i})$ et $w_{n}$$=$$d$
	\item $I'$ contient deux scénarios:\\
	    Pour le scénario1, les valeurs des objets sont définies comme suit: $v_{0}^1$$=$$n^3$d et $v_{i}^1$$=$0 pour tout $i$$=$1,...,$n$.\\
	    Pour le scénario2, la valeur de $v_{i}^2$ $=$ $n^2s(a_{i})$ pour tout $i$ $=$ 0,...,$n-1$ et
	     $v_{n}^2$ $=$ $n^2d$.\\ 
\end{itemize}
La valeur optimale de $I'$ égale à $n^3d$ dans le premier scénario et $n^2d$ dans le second scénario.
Le tableau suivant représente l'instance $I'$\\
\begin{table}	
\begin{center}
	\begin{tabular}{|c|c|c|c|}
    \hline
    $i$ & $w_{i}$ & $p_{i}^1$ & $p_{i}^2$ \\
    \hline
   0& s($a_{0}$) & n^3d & n^2s($a_{0}$)\\
     \hline
	1 & s($a_{1}$) & 0 & n^2s($a_{1}$)\\
\hline
	2 & s($a_{2}$) & 0 & n^2s($a_{2}$)\\
	  \hline
	3 & d & 0 & n^2d\\
	\hline
\end{tabular}
\end{center}
\caption {Représentation de l'instance min-max regret du problème sac à dos}
\end{table}\\
En deuxième étape, si j'ai une instance positive pour mon problème de décision partition c'est à dire j'ai une partition ($A'$,$A$ $\setminus$ $A'$) et qu'on suppose que $a_{0}$ $\in$ $A'$ alors la solution $ x^*$ qui correspond à $A'$ de $I'$ a pour $R_{max}(x^*)$$=$0 et donc opt($I'$)$=$0.\\
Sinon, si j'ai une instance négative et que la solution $x$ de $I'$ ne contient pas $a_{0}$ alors $R_{max}(x)$ $=$ $n^3d$. Sinon si la solution contient $a_{0}$ alors $R_{max}(x)$ $\geqslant$ $n^2$ et donc opt(I') $\geqslant$ $n^2$.  
\section{Nombre non constant de scénario}
	Kouvelis et Yu ont prouvé que min-max et min-max regret du plus court chemin ainsi que min-max de l'arbre couvrant de poids minimum et max-min du problème sac à dos sont fortement NP-difficiles dans le cas où le nombre de scénarios est non constant.
	\begin{thm}
	Min-Max regret du problème sac à dos est fortement NP-difficile pour un nombre non constant de scénarios.
	\end{thm}\\
Pour prouver ce résultat, on construit une gap-introducing reduction à partir du problème couverture des sommets qui est connu NP-complet. Une instance de ce problème est représenté par un graphe G$=$(V,E) et un entier positif $K$ où $v$ représente les sommets et $E$ les arêtes.\\
On définit une instance $I$ de min-max regret du problème de sac à dos de $n$ objets et un ensemble $m$ de scénarios. La valeur du poids de chaque objet $w_{i}$ est égale à 1 pour tout $i$$=$1,...$n$. La capacité du sac à dos $d$ $=$ $k$ et la valeur de chaque objet $i$ dans le scénario 
$$
$s_{j}$ $=$ 
\left\lbrace 
\begin{array}{r r r}
$1$    $si le noeud $i$ $\in$ $V$ est incident à l'arête $j$ $\in$ $E$ $\\
$0$
\end{array}
\right.   
$$
\subsection{Exemple numérique}
On prend $n$ $=$ 5 et $m$ $=$ 6
L'ensemble des aretes $E$ $=$ $\lbrace$ $\overbrace{(1,2)}$ $\overbrace{(1,5)$ $\overbrace{(2,3)}$ $\overbrace{(3,4)}$ $\overbrace{(4,5)}$ $\overbrace{(2,5)} $\rbrace$
\end{document}
